{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e0e1271-053c-4de2-994a-142de1b8787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import shap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec35a215-9c73-4dbb-b4d4-1031e4157b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_mvv_understanding</th>\n",
       "      <th>company_mvv_aplying</th>\n",
       "      <th>others_opinion_for_company</th>\n",
       "      <th>company_superiority</th>\n",
       "      <th>company_offer</th>\n",
       "      <th>company_constant_visual_image</th>\n",
       "      <th>company_expectation_from_employee</th>\n",
       "      <th>customers_expectation_from_employee</th>\n",
       "      <th>customer_perception_attitude</th>\n",
       "      <th>sales_dep</th>\n",
       "      <th>marketing_dep</th>\n",
       "      <th>services_dep</th>\n",
       "      <th>finance_dep</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_mvv_understanding  company_mvv_aplying  others_opinion_for_company  \\\n",
       "0                          5                    5                           3   \n",
       "1                          5                    5                           5   \n",
       "2                          5                    4                           5   \n",
       "3                          5                    5                           3   \n",
       "4                          3                    5                           5   \n",
       "\n",
       "   company_superiority  company_offer  company_constant_visual_image  \\\n",
       "0                    3              5                              5   \n",
       "1                    4              5                              5   \n",
       "2                    3              5                              3   \n",
       "3                    5              3                              5   \n",
       "4                    3              5                              4   \n",
       "\n",
       "   company_expectation_from_employee  customers_expectation_from_employee  \\\n",
       "0                                  5                                    5   \n",
       "1                                  5                                    5   \n",
       "2                                  5                                    5   \n",
       "3                                  5                                    5   \n",
       "4                                  5                                    5   \n",
       "\n",
       "   customer_perception_attitude  sales_dep  marketing_dep  services_dep  \\\n",
       "0                             4          1              0             0   \n",
       "1                             3          1              0             0   \n",
       "2                             5          1              0             0   \n",
       "3                             4          1              0             0   \n",
       "4                             3          1              0             0   \n",
       "\n",
       "   finance_dep  target  \n",
       "0            0       1  \n",
       "1            0       1  \n",
       "2            0       1  \n",
       "3            0       1  \n",
       "4            0       1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "# Import dataset\n",
    "filepath = os.path.join('..', 'datasets', 'brand_care.csv')\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Drop `ID` column\n",
    "df = df.drop(columns=['employee_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "664146ed-620b-4f2a-bb3b-9eff3787116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    763\n",
       "0    237\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class balance of 'target' col\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d655407-65ec-4ad6-8d62-56a9bcb0cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: (array([0, 1], dtype=int64), array([167, 538], dtype=int64))\n",
      "Validation class distribution: (array([0, 1], dtype=int64), array([ 34, 111], dtype=int64))\n",
      "Test class distribution: (array([0, 1], dtype=int64), array([ 36, 114], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 1. Isolate X variables\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "# 2. Isolate y variable\n",
    "y = df['target']\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_tr, X_test, y_tr, y_test = train_test_split(X, y, stratify=y,\n",
    "                                              test_size=0.15, random_state=42)\n",
    "\n",
    "# 4. Split into train and validate sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tr, y_tr, stratify=y_tr,\n",
    "                                                  test_size=0.17, random_state=42)\n",
    "\n",
    "# Print class distributions\n",
    "print(\"Train class distribution:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Validation class distribution:\", np.unique(y_val, return_counts=True))\n",
    "print(\"Test class distribution:\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f05f60f-7278-4676-b47f-ec3b1680829f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n",
      "145\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "for x in [X_train, X_val, X_test]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f71d3ff-b72b-4826-84d8-b3bc90a55f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (705, 13)\n",
      "Shape of y_train: (705,)\n",
      "Shape of X_val: (145, 13)\n",
      "Shape of y_val: (145,)\n",
      "Shape of X_test: (150, 13)\n",
      "Shape of y_test: (150,)\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_train = X_train_scaled\n",
    "\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_val = X_val_scaled\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test = X_test_scaled\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6718e5ef-bef8-47dc-abca-9e532928245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 13      # number of input features\n",
    "n_y = 1       # number of ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ab0b9c7-0cfb-4119-a1dd-e2c3e101fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n_h1, n_h2):\n",
    "    \n",
    "    # Define the input layer separately\n",
    "    input_layer = layers.Input(shape=(n_x,))  # Define the input layer explicitly\n",
    "\n",
    "    # Define the rest of the model\n",
    "    x = layers.Dense(n_h1, activation='relu')(input_layer)  # First hidden layer\n",
    "    x = layers.Dense(n_h2, activation='relu')(x)  # Second hidden layer\n",
    "    output_layer = layers.Dense(n_y, activation='sigmoid')(x)  # Output layer (binary classification)\n",
    "\n",
    "    # Create the model by specifying inputs and outputs\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=150, \n",
    "        batch_size=16, \n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Training set\n",
    "\n",
    "    # Get predictions\n",
    "    y_train_pred_probs = model.predict(X_train)  # Probabilities\n",
    "    y_train_pred = (y_train_pred_probs >= 0.5).astype(int)   # Convert to binary predictions\n",
    "\n",
    "    # Compute metrics\n",
    "    precision_train = precision_score(y_train, y_train_pred)\n",
    "    recall_train = recall_score(y_train, y_train_pred)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_train_pred_probs)\n",
    "\n",
    "    print(f\"Training Metrics:\")\n",
    "    print(f\"Precision: {precision_train:.4f}\")\n",
    "    print(f\"Recall: {recall_train:.4f}\")\n",
    "    print(f\"F1: {f1_train:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_train:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_train:.4f}\")\n",
    "\n",
    "\n",
    "    # Validation set\n",
    "\n",
    "    # Get predictions\n",
    "    y_val_pred_probs = model.predict(X_val)  # Probabilities\n",
    "    y_val_pred = (y_val_pred_probs >= 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "    # Compute metrics\n",
    "    precision_val = precision_score(y_val, y_val_pred)\n",
    "    recall_val = recall_score(y_val, y_val_pred)\n",
    "    f1_val = f1_score(y_val, y_val_pred)\n",
    "    accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "    roc_auc_val = roc_auc_score(y_val, y_val_pred_probs)\n",
    "\n",
    "    print(f\"Validation Metrics:\")\n",
    "    print(f\"Precision: {precision_val:.4f}\")\n",
    "    print(f\"Recall: {recall_val:.4f}\")\n",
    "    print(f\"F1: {f1_val:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_val:.4f}\")\n",
    "\n",
    "\n",
    "    # Test set\n",
    "\n",
    "    # Get predictions\n",
    "    y_test_pred_probs = model.predict(X_test)  # Probabilities\n",
    "    y_test_pred = (y_test_pred_probs >= 0.5).astype(int)  # Convert to binary predictions\n",
    "\n",
    "    # Compute metrics\n",
    "    precision_test = precision_score(y_test, y_test_pred)\n",
    "    recall_test = recall_score(y_test, y_test_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_pred_probs)\n",
    "\n",
    "    print(f\"Test Metrics:\")\n",
    "    print(f\"Precision: {precision_test:.4f}\")\n",
    "    print(f\"Recall: {recall_test:.4f}\")\n",
    "    print(f\"F1: {f1_test:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_test:.4f}\")\n",
    "\n",
    "    return model, accuracy_test, precision_test, recall_test, f1_test, roc_auc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a0cd5b91-3c35-4895-8b77-54a1adb8ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FNN with H1=26, H2=13\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Training Metrics:\n",
      "Precision: 0.9945\n",
      "Recall: 1.0000\n",
      "F1: 0.9972\n",
      "Accuracy: 0.9957\n",
      "ROC AUC: 0.9999\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Validation Metrics:\n",
      "Precision: 0.9402\n",
      "Recall: 0.9910\n",
      "F1: 0.9649\n",
      "Accuracy: 0.9448\n",
      "ROC AUC: 0.9918\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Test Metrics:\n",
      "Precision: 0.9565\n",
      "Recall: 0.9649\n",
      "F1: 0.9607\n",
      "Accuracy: 0.9400\n",
      "ROC AUC: 0.9817\n",
      "Training FNN with H1=39, H2=19\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Training Metrics:\n",
      "Precision: 0.9981\n",
      "Recall: 1.0000\n",
      "F1: 0.9991\n",
      "Accuracy: 0.9986\n",
      "ROC AUC: 1.0000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Validation Metrics:\n",
      "Precision: 0.9483\n",
      "Recall: 0.9910\n",
      "F1: 0.9692\n",
      "Accuracy: 0.9517\n",
      "ROC AUC: 0.9944\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Test Metrics:\n",
      "Precision: 0.9487\n",
      "Recall: 0.9737\n",
      "F1: 0.9610\n",
      "Accuracy: 0.9400\n",
      "ROC AUC: 0.9873\n",
      "Training FNN with H1=52, H2=26\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Training Metrics:\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1: 1.0000\n",
      "Accuracy: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Validation Metrics:\n",
      "Precision: 0.9730\n",
      "Recall: 0.9730\n",
      "F1: 0.9730\n",
      "Accuracy: 0.9586\n",
      "ROC AUC: 0.9944\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Test Metrics:\n",
      "Precision: 0.9646\n",
      "Recall: 0.9561\n",
      "F1: 0.9604\n",
      "Accuracy: 0.9400\n",
      "ROC AUC: 0.9883\n",
      "Best test results come from FNN (13,39,19,1)\n",
      "Precision: 0.9487\n",
      "Recall: 0.9737\n",
      "F1 Score: 0.9610\n",
      "Accuracy: 0.9400\n",
      "ROC_AUC: 0.9873\n",
      "   accuracy  precision    recall        f1   roc_auc\n",
      "0      0.94   0.948718  0.973684  0.961039  0.987329\n"
     ]
    }
   ],
   "source": [
    "n_h1=0\n",
    "n_h2=0\n",
    "best_results = {\n",
    "    'accuracy' : 0,\n",
    "    'precision' : 0,\n",
    "    'recall' : 0,\n",
    "    'f1' : 0,\n",
    "    'roc_auc' : 0\n",
    "}\n",
    "sum_best_results = 0\n",
    "h1_candidates = [2 * n_x, 3 * n_x, 4 * n_x]\n",
    "h2_candidates = [h1 // 2 for h1 in h1_candidates]\n",
    "\n",
    "for h1, h2 in zip(h1_candidates, h2_candidates):\n",
    "    print(f\"Training FNN with H1={h1}, H2={h2}\")\n",
    "    \n",
    "    model, accuracy, precision, recall, f1, roc_auc = predict(h1, h2)\n",
    "    \n",
    "    sum_results = accuracy + precision + recall + f1 + roc_auc\n",
    "    \n",
    "    if sum_results > sum_best_results:\n",
    "        sum_best_results = sum_results\n",
    "        best_results['roc_auc'] = roc_auc\n",
    "        best_results['accuracy'] = accuracy\n",
    "        best_results['precision'] = precision\n",
    "        best_results['recall'] = recall\n",
    "        best_results['f1'] = f1\n",
    "        n_h1 = h1\n",
    "        n_h2 = h2\n",
    "            \n",
    "\n",
    "print(f'Best test results come from FNN ({n_x},{n_h1},{n_h2},{n_y})')\n",
    "\n",
    "print(f'Precision: {best_results[\"precision\"]:.4f}')\n",
    "print(f'Recall: {best_results[\"recall\"]:.4f}')\n",
    "print(f'F1 Score: {best_results[\"f1\"]:.4f}')\n",
    "print(f'Accuracy: {best_results[\"accuracy\"]:.4f}')\n",
    "print(f'ROC_AUC: {best_results[\"roc_auc\"]:.4f}')\n",
    "\n",
    "results_df = pd.DataFrame([best_results])  # Use [best_results] to make it a single-row DataFrame\n",
    "\n",
    "# Step 3: Export to Excel\n",
    "results_df.to_excel('bc_best_FNN_results.xlsx', index=False)\n",
    "\n",
    "# Optional: Display DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f78ebf8-bd67-460c-8829-074d9655cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_to_probability_delta(shap_val):\n",
    "    return np.tanh(shap_val)  # maps raw SHAP value to ~[-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c3afcc5-3098-45be-a8e4-722e229821e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Imp. %</th>\n",
       "      <th>Imp. Direct.</th>\n",
       "      <th>Imp. Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sales_dep</td>\n",
       "      <td>29.5</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services_dep</td>\n",
       "      <td>26.1</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company_mvv_aplying</td>\n",
       "      <td>14.8</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>company_mvv_understanding</td>\n",
       "      <td>11.7</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>company_offer</td>\n",
       "      <td>11.4</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>company_expectation_from_employee</td>\n",
       "      <td>9.6</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>company_superiority</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>others_opinion_for_company</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Inc.</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>finance_dep</td>\n",
       "      <td>26.5</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marketing_dep</td>\n",
       "      <td>25.3</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>customers_expectation_from_employee</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>company_constant_visual_image</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>customer_perception_attitude</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Dec.</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Imp. % Imp. Direct. Imp. Strength\n",
       "0                             sales_dep    29.5         Inc.          High\n",
       "1                          services_dep    26.1         Inc.          High\n",
       "2                   company_mvv_aplying    14.8         Inc.          High\n",
       "3             company_mvv_understanding    11.7         Inc.        Medium\n",
       "4                         company_offer    11.4         Inc.        Medium\n",
       "5     company_expectation_from_employee     9.6         Inc.        Medium\n",
       "6                   company_superiority     5.8         Inc.           Low\n",
       "7            others_opinion_for_company     4.0         Inc.           Low\n",
       "8                           finance_dep    26.5         Dec.          High\n",
       "9                         marketing_dep    25.3         Dec.          High\n",
       "10  customers_expectation_from_employee     9.0         Dec.        Medium\n",
       "11        company_constant_visual_image     6.6         Dec.           Low\n",
       "12         customer_perception_attitude     5.2         Dec.           Low"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample background data from training set (DeepExplainer needs this for reference)\n",
    "background = X_train[:100]\n",
    "\n",
    "# Initialize SHAP DeepExplainer\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Compute SHAP values for the dataset you want to explain (usually X_train or X_test)\n",
    "shap_values = explainer.shap_values(X_train)  # Ensure data is in NumPy format\n",
    "\n",
    "# Extract SHAP values for class 1 (positive class) from shap_values\n",
    "shap_values_class_1 = shap_values[:, :, 0]\n",
    "\n",
    "# Compute the mean SHAP value per feature (across all samples)\n",
    "mean_shap_values = np.mean(shap_values_class_1, axis=0)  # Mean SHAP value per feature for positive class\n",
    "\n",
    "# Compute mean absolute SHAP values per feature\n",
    "mean_abs_shap_values = np.mean(np.abs(shap_values_class_1), axis=0)  # Mean absolute SHAP values per feature\n",
    "\n",
    "# Direction: 'Increases' if the mean SHAP value for a feature is positive, 'Decreases' otherwise\n",
    "direction = ['Inc.' if val > 0 else 'Dec.' for val in mean_shap_values]\n",
    "\n",
    "# Binning the impact into categories (Low, Medium, High) based on quantiles of the mean absolute SHAP values\n",
    "impact_strength = pd.qcut(mean_abs_shap_values, q=3, labels=[\"Low\", \"Medium\", \"High\"])\n",
    "\n",
    "# Create a DataFrame to summarize the SHAP values for each feature\n",
    "shap_summary_df = pd.DataFrame({\n",
    "'Feature': X.columns,  # Features in the dataset\n",
    "'Imp. %': np.round(shap_to_probability_delta(mean_abs_shap_values)*100, 1),  # Impact percentage for each feature\n",
    "'Imp. Direct.': direction,  # Impact direction based on mean SHAP values\n",
    "'Imp. Strength': impact_strength  # Categorized impact strength (Low, Medium, High)\n",
    "}).sort_values(by=['Imp. Direct.', 'Imp. %'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save the SHAP summary to Excel for further inspection\n",
    "shap_summary_df.to_excel('bc_shap_summary_fnn.xlsx', index=False)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "shap_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ba51d-9106-4405-b23d-1cddefcad300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
